# -*- coding: utf-8 -*-
from __future__ import annotations

import os
from typing import List, Tuple

from dotenv import load_dotenv
from openai import OpenAI

from .prompts import SYSTEM_PROMPT, REFUSAL_TEXT
from .retriever import (
    fetch_doc_if_needed,
    build_chunks,
    build_faiss_index,
    search_topk,
)
from .utils import format_context

MODEL = "gpt-4o-mini"
SIM_THRESHOLD = 0.30  # –µ—Å–ª–∏ –ª—É—á—à–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∏–∂–µ ‚Äî —Å—á–∏—Ç–∞–µ–º –≤–æ–ø—Ä–æ—Å "–≤–Ω–µ —Ç–µ–º—ã"


def build_indices():
    """–ì–æ—Ç–æ–≤–∏–º –¥–≤–∞ –∏–Ω–¥–µ–∫—Å–∞: –¥–ª—è rc –∏ –¥–ª—è tok, —á—Ç–æ–±—ã –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ '2 —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞'."""
    text = fetch_doc_if_needed()
    chunks_rc = build_chunks(text, mode="rc")
    chunks_tok = build_chunks(text, mode="tok")
    vindex_rc = build_faiss_index(chunks_rc)
    vindex_tok = build_faiss_index(chunks_tok)
    return vindex_rc, vindex_tok


def answer_with_context(
    client: OpenAI,
    question: str,
    ctx: List[Tuple[str, float]],
    memory: List[dict],
) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç –∏–∑ —Å–∏—Å—Ç–µ–º–∫–∏ + –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ + –∏—Å—Ç–æ—Ä–∏–∏ –∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å (openai>=2.x)."""
    context_text = format_context(ctx)
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç (—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞):\n{context_text}"},
    ]
    # –¥–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    for m in memory[-6:]:
        messages.append(m)
    # —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å
    messages.append({"role": "user", "content": question})

    response = client.chat.completions.create(
        model=MODEL,
        messages=messages,
    )
    return response.choices[0].message.content.strip()


def main():
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω OPENAI_API_KEY –≤ .env")
    client = OpenAI(api_key=api_key)

    print("–ì–æ—Ç–æ–≤–ª—é –∏–Ω–¥–µ–∫—Å—ã (–¥–≤–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å–ø–ª–∏—Ç—Ç–∏–Ω–≥–∞: rc –∏ tok)...")
    vindex_rc, vindex_tok = build_indices()
    active = "rc"  # —Ç–µ–∫—É—â–∏–π –∏–Ω–¥–µ–∫—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    print("–ì–æ—Ç–æ–≤–æ. –ê–∫—Ç–∏–≤–Ω—ã–π —Å–ø–ª–∏—Ç—Ç–µ—Ä: rc (–ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å: /split rc|tok). –í—ã–π—Ç–∏: /exit")

    memory: List[dict] = []  # –∏—Å—Ç–æ—Ä–∏—è –ø–µ—Ä–µ–ø–∏—Å–∫–∏ (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞)

    while True:
        user_q = input("\n–í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
        if not user_q:
            continue
        if user_q.lower() in ("/exit", "exit", "quit"):
            print("–í—ã—Ö–æ–¥.")
            break
        if user_q.lower().startswith("/split"):
            _, *rest = user_q.split()
            if rest and rest[0] in ("rc", "tok"):
                active = rest[0]
                print(f"–ê–∫—Ç–∏–≤–Ω—ã–π —Å–ø–ª–∏—Ç—Ç–µ—Ä: {active}")
            else:
                print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /split rc  –∏–ª–∏  /split tok")
            continue

        # 1) –†–µ—Ç—Ä–∏–≤ —Å –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        vindex = vindex_rc if active == "rc" else vindex_tok
        ctx = search_topk(vindex, user_q, k=5)
        best_score = ctx[0][1] if ctx else 0.0

        # 2) –§–∏–ª—å—Ç—Ä "–≤–æ–ø—Ä–æ—Å –≤–Ω–µ —Ç–µ–º—ã"
        if best_score < SIM_THRESHOLD:
            print(REFUSAL_TEXT)

            # –ø–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–∞
            memory.append({"role": "user", "content": user_q})
            memory.append({"role": "assistant", "content": REFUSAL_TEXT})

            # üßæ –ª–æ–≥–∏—Ä—É–µ–º –¥–∞–∂–µ "–≤–Ω–µ —Ç–µ–º—ã"
            os.makedirs("outputs", exist_ok=True)
            with open("outputs/transcript.txt", "a", encoding="utf-8") as f:
                f.write(f"Q: {user_q}\n")
                f.write("best_score: NONE (–≤–æ–ø—Ä–æ—Å –≤–Ω–µ —Ç–µ–º—ã)\n")
                f.write(f"A: {REFUSAL_TEXT}\n")
                f.write("-" * 40 + "\n")
            print("\n[–õ–æ–≥ –æ–±–Ω–æ–≤–ª—ë–Ω: outputs/transcript.txt]")
            continue
        else:
            # 3) –û—Ç–≤–µ—Ç —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –∏—Å—Ç–æ—Ä–∏–∏
            answer = answer_with_context(client, user_q, ctx, memory)
            print("\n–û—Ç–≤–µ—Ç:\n", answer)

            # 4) –ü–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–∞
            memory.append({"role": "user", "content": user_q})
            memory.append({"role": "assistant", "content": answer})

            # 5) –õ—ë–≥–∫–∏–π –ª–æ–≥ –≤ —Ñ–∞–π–ª (–¥–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
            os.makedirs("outputs", exist_ok=True)
            with open("outputs/transcript.txt", "a", encoding="utf-8") as f:
                f.write(f"Q: {user_q}\n")
                f.write(f"best_score: {best_score:.3f}  [split={active}]\n")
                f.write(f"A: {answer}\n")
                f.write("-" * 40 + "\n")
            print("\n[–õ–æ–≥ –æ–±–Ω–æ–≤–ª—ë–Ω: outputs/transcript.txt]")


if __name__ == "__main__":
    main()
